{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Anonymity Implementation: Massachusetts GIC Case Study\n",
    "\n",
    "This interactive notebook demonstrates **k-anonymity**, a privacy-preserving technique that protects against linkage attacks by generalizing quasi-identifiers.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**K-anonymity** ensures that each record in a dataset is indistinguishable from at least k-1 other records based on quasi-identifying attributes (Age, ZipCode, Gender).\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Quasi-Identifiers (QI)**: Attributes that can be linked to external data (e.g., Age, ZipCode, Gender)\n",
    "- **Equivalence Class**: Group of records with identical QI values\n",
    "- **Generalization**: Making data less specific (e.g., Age 29 → 20-39)\n",
    "- **Suppression**: Removing records that can't be anonymized\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Medical Dataset\n",
    "\n",
    "This dataset is inspired by the **Massachusetts GIC case** where Governor William Weld's medical records were re-identified by linking voter registration data with anonymized hospital records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Medical Dataset (Massachusetts GIC Case)\n",
    "data = {\n",
    "    'Name': ['Alice Johnson', 'Betty Smith', 'Carol Williams', 'David Brown', \n",
    "             'Edward Davis', 'Frank Miller', 'George Wilson', 'Helen Moore',\n",
    "             'Ian Taylor', 'Jane Anderson', 'Kevin Thomas', 'Laura Jackson',\n",
    "             'Michael White', 'Nancy Harris', 'Oliver Martin'],\n",
    "    'ZipCode': ['02138', '02139', '02141', '02142', '02138', '02139', '02141', \n",
    "                '02142', '02138', '02139', '02141', '02142', '02138', '02139', '02141'],\n",
    "    'Age': [29, 31, 28, 45, 47, 43, 52, 36, 41, 33, 55, 38, 49, 42, 58],\n",
    "    'Gender': ['Female', 'Female', 'Female', 'Male', 'Male', 'Male', 'Male', \n",
    "               'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Disease': ['Ovarian Cancer', 'Breast Cancer', 'Ovarian Cancer', 'Heart Disease',\n",
    "                'Heart Disease', 'Diabetes', 'Heart Disease', 'Diabetes', \n",
    "                'Prostate Cancer', 'Breast Cancer', 'Heart Disease', 'Diabetes',\n",
    "                'Prostate Cancer', 'Breast Cancer', 'Diabetes']\n",
    "}\n",
    "\n",
    "df_original = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Dataset contains {len(df_original)} patient records\")\n",
    "print(f\"Attributes: {list(df_original.columns)}\")\n",
    "print(\"\\nFirst 5 records:\")\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataset\n",
    "print(\"ORIGINAL DATASET (Before Anonymization)\")\n",
    "print(\"=\" * 80)\n",
    "df_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generalization Functions\n",
    "\n",
    "Generalization hierarchies for quasi-identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_age(age: int, level: int) -> str:\n",
    "    \"\"\"\n",
    "    Generalize age based on hierarchy level.\n",
    "    Level 0: Exact age (e.g., 29)\n",
    "    Level 1: 5-year ranges (e.g., 25-29)\n",
    "    Level 2: 10-year ranges (e.g., 20-29)\n",
    "    Level 3: 20-year ranges (e.g., 20-39)\n",
    "    \"\"\"\n",
    "    if level == 0:\n",
    "        return str(age)\n",
    "    elif level == 1:\n",
    "        lower = (age // 5) * 5\n",
    "        return f\"{lower}-{lower+4}\"\n",
    "    elif level == 2:\n",
    "        lower = (age // 10) * 10\n",
    "        return f\"{lower}-{lower+9}\"\n",
    "    elif level == 3:\n",
    "        if age < 40:\n",
    "            return \"20-39\"\n",
    "        elif age < 60:\n",
    "            return \"40-59\"\n",
    "        else:\n",
    "            return \"60+\"\n",
    "    return str(age)\n",
    "\n",
    "def generalize_zipcode(zipcode: str, level: int) -> str:\n",
    "    \"\"\"\n",
    "    Generalize ZIP code based on hierarchy level.\n",
    "    Level 0: Full 5-digit (e.g., 02138)\n",
    "    Level 1: 4-digit prefix (e.g., 0213*)\n",
    "    Level 2: 3-digit prefix (e.g., 021**)\n",
    "    Level 3: 2-digit prefix (e.g., 02***)\n",
    "    \"\"\"\n",
    "    if level == 0:\n",
    "        return zipcode\n",
    "    elif level == 1:\n",
    "        return zipcode[:4] + \"*\"\n",
    "    elif level == 2:\n",
    "        return zipcode[:3] + \"**\"\n",
    "    elif level == 3:\n",
    "        return zipcode[:2] + \"***\"\n",
    "    return zipcode\n",
    "\n",
    "# Test generalization functions\n",
    "print(\"Age Generalization Examples:\")\n",
    "print(f\"  Level 0: {generalize_age(29, 0)}\")\n",
    "print(f\"  Level 1: {generalize_age(29, 1)}\")\n",
    "print(f\"  Level 2: {generalize_age(29, 2)}\")\n",
    "print(f\"  Level 3: {generalize_age(29, 3)}\")\n",
    "\n",
    "print(\"\\nZIP Code Generalization Examples:\")\n",
    "print(f\"  Level 0: {generalize_zipcode('02138', 0)}\")\n",
    "print(f\"  Level 1: {generalize_zipcode('02138', 1)}\")\n",
    "print(f\"  Level 2: {generalize_zipcode('02138', 2)}\")\n",
    "print(f\"  Level 3: {generalize_zipcode('02138', 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Anonymity Core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_equivalence_classes(df: pd.DataFrame, qi_columns: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate equivalence classes based on quasi-identifiers.\n",
    "    Returns dictionary mapping QI combination to list of indices.\n",
    "    \"\"\"\n",
    "    equivalence_classes = {}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        qi_tuple = tuple(row[qi_columns].values)\n",
    "        if qi_tuple not in equivalence_classes:\n",
    "            equivalence_classes[qi_tuple] = []\n",
    "        equivalence_classes[qi_tuple].append(idx)\n",
    "    \n",
    "    return equivalence_classes\n",
    "\n",
    "def check_k_anonymity(df: pd.DataFrame, qi_columns: List[str], k: int) -> Tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    Check if dataset satisfies k-anonymity.\n",
    "    Returns (is_k_anonymous, min_group_size).\n",
    "    \"\"\"\n",
    "    eq_classes = calculate_equivalence_classes(df, qi_columns)\n",
    "    min_size = min(len(indices) for indices in eq_classes.values())\n",
    "    \n",
    "    return min_size >= k, min_size\n",
    "\n",
    "print(\"✓ K-anonymity verification functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_anonymize(df: pd.DataFrame, k: int, qi_columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply k-anonymity through generalization and suppression.\n",
    "    Uses a greedy approach that generalizes quasi-identifiers and\n",
    "    suppresses records in small equivalence classes if needed.\n",
    "    \"\"\"\n",
    "    df_anon = df.copy()\n",
    "\n",
    "    # Generalization levels for each QI attribute\n",
    "    age_level = 0\n",
    "    zip_level = 0\n",
    "    gender_generalized = False\n",
    "\n",
    "    # Iteratively generalize until k-anonymity is achieved\n",
    "    max_iterations = 20\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iterations:\n",
    "        # Apply current generalization levels\n",
    "        df_anon['Age_Gen'] = df_anon['Age'].apply(lambda x: generalize_age(x, age_level))\n",
    "        df_anon['ZipCode_Gen'] = df_anon['ZipCode'].apply(lambda x: generalize_zipcode(x, zip_level))\n",
    "\n",
    "        # Generalize gender if needed\n",
    "        if gender_generalized:\n",
    "            df_anon['Gender_Gen'] = 'Person'\n",
    "        else:\n",
    "            df_anon['Gender_Gen'] = df_anon['Gender']\n",
    "\n",
    "        # Check k-anonymity with generalized attributes\n",
    "        qi_gen = ['Age_Gen', 'ZipCode_Gen', 'Gender_Gen']\n",
    "        eq_classes = calculate_equivalence_classes(df_anon, qi_gen)\n",
    "\n",
    "        # Find equivalence classes smaller than k\n",
    "        small_classes = {qi: indices for qi, indices in eq_classes.items()\n",
    "                        if len(indices) < k}\n",
    "\n",
    "        if not small_classes:\n",
    "            # k-anonymity achieved!\n",
    "            df_final = df_anon.copy()\n",
    "            df_final['Age'] = df_final['Age_Gen']\n",
    "            df_final['ZipCode'] = df_final['ZipCode_Gen']\n",
    "            df_final['Gender'] = df_final['Gender_Gen']\n",
    "            df_final = df_final.drop(columns=['Age_Gen', 'ZipCode_Gen', 'Gender_Gen', 'Name'])\n",
    "            return df_final\n",
    "\n",
    "        # Strategy: Try more generalization first, then suppression as last resort\n",
    "        if age_level < 3:\n",
    "            age_level += 1\n",
    "        elif zip_level < 3:\n",
    "            zip_level += 1\n",
    "        elif not gender_generalized:\n",
    "            gender_generalized = True\n",
    "        else:\n",
    "            # Last resort: suppress records in small equivalence classes\n",
    "            indices_to_suppress = []\n",
    "            for indices in small_classes.values():\n",
    "                indices_to_suppress.extend(indices)\n",
    "\n",
    "            df_anon = df_anon.drop(index=indices_to_suppress).reset_index(drop=True)\n",
    "\n",
    "            # Recheck with suppressed records\n",
    "            df_anon['Age_Gen'] = df_anon['Age'].apply(lambda x: generalize_age(x, age_level))\n",
    "            df_anon['ZipCode_Gen'] = df_anon['ZipCode'].apply(lambda x: generalize_zipcode(x, zip_level))\n",
    "            if gender_generalized:\n",
    "                df_anon['Gender_Gen'] = 'Person'\n",
    "            else:\n",
    "                df_anon['Gender_Gen'] = df_anon['Gender']\n",
    "\n",
    "            df_final = df_anon.copy()\n",
    "            df_final['Age'] = df_final['Age_Gen']\n",
    "            df_final['ZipCode'] = df_final['ZipCode_Gen']\n",
    "            df_final['Gender'] = df_final['Gender_Gen']\n",
    "            df_final = df_final.drop(columns=['Age_Gen', 'ZipCode_Gen', 'Gender_Gen', 'Name'])\n",
    "            return df_final\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    # If max iterations reached (shouldn't happen with suppression), return what we have\n",
    "    df_final = df_anon.copy()\n",
    "    df_final['Age'] = df_final['Age_Gen']\n",
    "    df_final['ZipCode'] = df_final['ZipCode_Gen']\n",
    "    df_final['Gender'] = df_final['Gender_Gen']\n",
    "    df_final = df_final.drop(columns=['Age_Gen', 'ZipCode_Gen', 'Gender_Gen', 'Name'])\n",
    "    return df_final\n",
    "\n",
    "print(\"✓ K-anonymization algorithm defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Privacy and Utility Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discernibility_metric(df: pd.DataFrame, qi_columns: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate discernibility metric (lower is better for utility).\n",
    "    Each record gets penalty equal to its equivalence class size squared.\n",
    "    \"\"\"\n",
    "    eq_classes = calculate_equivalence_classes(df, qi_columns)\n",
    "    total_cost = sum(len(indices) ** 2 for indices in eq_classes.values())\n",
    "    return total_cost\n",
    "\n",
    "def calculate_precision_loss(original_df: pd.DataFrame, anon_df: pd.DataFrame) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate precision loss for each generalized attribute.\n",
    "    \"\"\"\n",
    "    precision_loss = {}\n",
    "    \n",
    "    # Age precision loss\n",
    "    if 'Age' in anon_df.columns:\n",
    "        original_unique = original_df['Age'].nunique()\n",
    "        anon_unique = anon_df['Age'].nunique()\n",
    "        precision_loss['Age'] = 1 - (anon_unique / original_unique)\n",
    "    \n",
    "    # ZipCode precision loss\n",
    "    if 'ZipCode' in anon_df.columns:\n",
    "        original_unique = original_df['ZipCode'].nunique()\n",
    "        anon_unique = anon_df['ZipCode'].nunique()\n",
    "        precision_loss['ZipCode'] = 1 - (anon_unique / original_unique)\n",
    "    \n",
    "    return precision_loss\n",
    "\n",
    "def calculate_reidentification_probability(k: int) -> float:\n",
    "    \"\"\"Calculate maximum re-identification probability for k-anonymous data.\"\"\"\n",
    "    return 1.0 / k\n",
    "\n",
    "print(\"✓ Metric calculation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Original Dataset K-Anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qi_original = ['ZipCode', 'Age', 'Gender']\n",
    "df_check = df_original[qi_original + ['Disease']].copy()\n",
    "is_anon_orig, min_size_orig = check_k_anonymity(df_check, qi_original, 2)\n",
    "\n",
    "print(\"ORIGINAL DATASET K-ANONYMITY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"K-Anonymity Check (k=2): {'✓ PASS' if is_anon_orig else '✗ FAIL'}\")\n",
    "print(f\"Minimum equivalence class size: {min_size_orig}\")\n",
    "print()\n",
    "print(\"⚠️ The original dataset does NOT satisfy k-anonymity (k=2)\")\n",
    "print(\"   This makes it vulnerable to linkage attacks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply K-Anonymization (k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "print(f\"Applying k-anonymization with k={k}...\")\n",
    "df_k3 = k_anonymize(df_original, k, qi_original)\n",
    "\n",
    "print(f\"\\nANONYMIZED DATASET (k={k})\")\n",
    "print(\"=\" * 80)\n",
    "df_k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify k-anonymity\n",
    "qi_anon = ['ZipCode', 'Age', 'Gender']\n",
    "is_anon, min_size = check_k_anonymity(df_k3, qi_anon, k)\n",
    "\n",
    "print(f\"K-Anonymity Verification (k={k}): {'✓ PASS' if is_anon else '✗ FAIL'}\")\n",
    "print(f\"Minimum equivalence class size: {min_size}\")\n",
    "print()\n",
    "\n",
    "# Calculate metrics\n",
    "df_orig_check = df_original[qi_original + ['Disease']].copy()\n",
    "discern_orig = calculate_discernibility_metric(df_orig_check, qi_original)\n",
    "discern_anon = calculate_discernibility_metric(df_k3, qi_anon)\n",
    "precision = calculate_precision_loss(df_original, df_k3)\n",
    "reident_prob = calculate_reidentification_probability(k)\n",
    "\n",
    "print(\"PRIVACY METRICS:\")\n",
    "print(f\"  • Re-identification Probability: {reident_prob:.2%} (1/{k})\")\n",
    "print(f\"  • Privacy Gain: {(1 - reident_prob):.2%}\")\n",
    "print()\n",
    "\n",
    "print(\"UTILITY METRICS:\")\n",
    "print(f\"  • Discernibility Cost (Original): {discern_orig:.0f}\")\n",
    "print(f\"  • Discernibility Cost (Anonymized): {discern_anon:.0f}\")\n",
    "print(f\"  • Information Loss Increase: {((discern_anon - discern_orig) / discern_orig * 100):.1f}%\")\n",
    "print(f\"  • Age Precision Loss: {precision.get('Age', 0):.2%}\")\n",
    "print(f\"  • ZipCode Precision Loss: {precision.get('ZipCode', 0):.2%}\")\n",
    "print()\n",
    "\n",
    "# Show equivalence classes\n",
    "eq_classes = calculate_equivalence_classes(df_k3, qi_anon)\n",
    "print(f\"EQUIVALENCE CLASSES ({len(eq_classes)} groups):\")\n",
    "for i, (qi_combo, indices) in enumerate(eq_classes.items(), 1):\n",
    "    print(f\"  Class {i}: {qi_combo} → {len(indices)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Apply K-Anonymization (k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "print(f\"Applying k-anonymization with k={k}...\")\n",
    "df_k5 = k_anonymize(df_original, k, qi_original)\n",
    "\n",
    "print(f\"\\nANONYMIZED DATASET (k={k})\")\n",
    "print(\"=\" * 80)\n",
    "df_k5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify k-anonymity\n",
    "is_anon, min_size = check_k_anonymity(df_k5, qi_anon, k)\n",
    "\n",
    "print(f\"K-Anonymity Verification (k={k}): {'✓ PASS' if is_anon else '✗ FAIL'}\")\n",
    "print(f\"Minimum equivalence class size: {min_size}\")\n",
    "print()\n",
    "\n",
    "# Calculate metrics\n",
    "discern_anon_k5 = calculate_discernibility_metric(df_k5, qi_anon)\n",
    "precision_k5 = calculate_precision_loss(df_original, df_k5)\n",
    "reident_prob_k5 = calculate_reidentification_probability(k)\n",
    "\n",
    "print(\"PRIVACY METRICS:\")\n",
    "print(f\"  • Re-identification Probability: {reident_prob_k5:.2%} (1/{k})\")\n",
    "print(f\"  • Privacy Gain: {(1 - reident_prob_k5):.2%}\")\n",
    "print()\n",
    "\n",
    "print(\"UTILITY METRICS:\")\n",
    "print(f\"  • Discernibility Cost (Original): {discern_orig:.0f}\")\n",
    "print(f\"  • Discernibility Cost (Anonymized): {discern_anon_k5:.0f}\")\n",
    "print(f\"  • Information Loss Increase: {((discern_anon_k5 - discern_orig) / discern_orig * 100):.1f}%\")\n",
    "print(f\"  • Age Precision Loss: {precision_k5.get('Age', 0):.2%}\")\n",
    "print(f\"  • ZipCode Precision Loss: {precision_k5.get('ZipCode', 0):.2%}\")\n",
    "print()\n",
    "\n",
    "# Show equivalence classes\n",
    "eq_classes_k5 = calculate_equivalence_classes(df_k5, qi_anon)\n",
    "print(f\"EQUIVALENCE CLASSES ({len(eq_classes_k5)} groups):\")\n",
    "for i, (qi_combo, indices) in enumerate(eq_classes_k5.items(), 1):\n",
    "    print(f\"  Class {i}: {qi_combo} → {len(indices)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations\n",
    "\n",
    "### 9.1 Equivalence Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalence class distribution comparison\n",
    "k3_classes = [len(indices) for indices in eq_classes.values()]\n",
    "k5_classes = [len(indices) for indices in eq_classes_k5.values()]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot for k=3\n",
    "class_labels_k3 = [f'Class {i+1}' for i in range(len(k3_classes))]\n",
    "colors_k3 = plt.cm.Set3(np.linspace(0, 1, len(k3_classes)))\n",
    "\n",
    "ax1.bar(class_labels_k3, k3_classes, color=colors_k3, edgecolor='black', linewidth=1.5)\n",
    "ax1.axhline(y=3, color='red', linestyle='--', linewidth=2, label='k=3 threshold')\n",
    "ax1.set_ylabel('Number of Records', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Equivalence Class Distribution (k=3)', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(k3_classes):\n",
    "    ax1.text(i, v + 0.2, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot for k=5\n",
    "class_labels_k5 = [f'Class {i+1}' for i in range(len(k5_classes))]\n",
    "colors_k5 = plt.cm.Set2(np.linspace(0, 1, len(k5_classes)))\n",
    "\n",
    "ax2.bar(class_labels_k5, k5_classes, color=colors_k5, edgecolor='black', linewidth=1.5)\n",
    "ax2.axhline(y=5, color='red', linestyle='--', linewidth=2, label='k=5 threshold')\n",
    "ax2.set_ylabel('Number of Records', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Equivalence Class Distribution (k=5)', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(k5_classes):\n",
    "    ax2.text(i, v + 0.2, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Record Grouping into Equivalence Classes', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Privacy-Utility Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privacy vs Utility comparison\n",
    "k_values = [3, 5]\n",
    "privacy_scores = [66.7, 80.0]  # Privacy gain (1 - 1/k) * 100\n",
    "reident_probs = [33.3, 20.0]   # Re-identification probability\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Privacy gain\n",
    "bars = ax1.bar([f'k={k}' for k in k_values], privacy_scores, \n",
    "               color=['#2ecc71', '#27ae60'], alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_ylabel('Privacy Gain (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Privacy Protection Level', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, score in zip(bars, privacy_scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{score:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Re-identification probability\n",
    "bars2 = ax2.bar([f'k={k}' for k in k_values], reident_probs, \n",
    "                color=['#e74c3c', '#c0392b'], alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('Re-identification Probability (%)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Attack Success Probability', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, prob in zip(bars2, reident_probs):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{prob:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Privacy-Utility Tradeoff Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Data Generalization Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique values before and after\n",
    "attributes = ['ZIP Code', 'Age', 'Gender']\n",
    "original_unique = [\n",
    "    df_original['ZipCode'].nunique(),\n",
    "    df_original['Age'].nunique(),\n",
    "    df_original['Gender'].nunique()\n",
    "]\n",
    "k3_unique = [\n",
    "    df_k3['ZipCode'].nunique(),\n",
    "    df_k3['Age'].nunique(),\n",
    "    df_k3['Gender'].nunique()\n",
    "]\n",
    "k5_unique = [\n",
    "    df_k5['ZipCode'].nunique(),\n",
    "    df_k5['Age'].nunique(),\n",
    "    df_k5['Gender'].nunique()\n",
    "]\n",
    "\n",
    "x = np.arange(len(attributes))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width, original_unique, width, label='Original', \n",
    "               color='#3498db', edgecolor='black')\n",
    "bars2 = ax.bar(x, k3_unique, width, label='k=3 Anonymized', \n",
    "               color='#e67e22', edgecolor='black')\n",
    "bars3 = ax.bar(x + width, k5_unique, width, label='k=5 Anonymized', \n",
    "               color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Number of Distinct Values', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Attribute Generalization Impact on Data Specificity', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(attributes, fontsize=11)\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Privacy Protection**: K-anonymity successfully reduces re-identification probability from ~100% to 1/k\n",
    "   - k=3: 33.3% re-identification probability\n",
    "   - k=5: 20.0% re-identification probability\n",
    "\n",
    "2. **Data Utility Cost**: Higher k values provide stronger privacy but reduce data utility:\n",
    "   - More aggressive generalization (Age, ZipCode, Gender → \"Person\")\n",
    "   - Fewer distinct values in quasi-identifiers\n",
    "   - Higher information loss\n",
    "\n",
    "3. **Defense Mechanism**: K-anonymity defends against linkage attacks by:\n",
    "   - Creating equivalence classes of indistinguishable records\n",
    "   - Generalizing quasi-identifiers to reduce specificity\n",
    "   - Ensuring each record matches at least k-1 other records\n",
    "\n",
    "### Trade-offs:\n",
    "\n",
    "- **Security ↑** → **Utility ↓**: Increasing k improves privacy but reduces data granularity\n",
    "- **Optimal k**: Depends on use case (research vs. public release vs. regulatory compliance)\n",
    "\n",
    "### Limitations of K-Anonymity:\n",
    "\n",
    "- **Homogeneity Attack**: All records in equivalence class have same sensitive value\n",
    "- **Background Knowledge Attack**: Attacker knows victim is in dataset\n",
    "- **Composition Attack**: Multiple releases can be combined to re-identify\n",
    "\n",
    "**Next Steps**: Consider stronger privacy models like ℓ-diversity or t-closeness for additional protection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
